authors:
- Hakan Inan
- Khashayar Khosravi
- R. Socher
badges:
- id: OPEN_ACCESS
corpusId: 7443908
fieldsOfStudy:
- Computer Science
meta_key: 2017-tying-word-vectors-and-word-classifiers-a-loss-framework-for-language-modeling
numCitedBy: 337
numCiting: 34
paperAbstract: Recurrent neural networks have been very successful at predicting sequences of words in tasks such as language modeling. However, all such models are based on the conventional classification framework, where the model is trained against one-hot targets, and each word is represented both as an input and as an output in isolation. This causes inefficiencies in learning both in terms of utilizing all of the information and in terms of the number of parameters needed to train. We introduce a novel theoretical framework that facilitates better learning in language modeling, and show that our framework leads to tying together the input embedding and the output projection matrices, greatly reducing the number of trainable variables. Our framework leads to state of the art performance on the Penn Treebank with a variety of network models.
ref_count: 34
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: 2012-context-dependent-recurrent-neural-network-language-model
  numCitedBy: 550
  pid: d1275b2a2ab53013310e759e5c6878b96df643d4
  show_ref_link: false
  title: Context dependent recurrent neural network language model
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-using-the-output-embedding-to-improve-language-models
  numCitedBy: 574
  pid: 63e39cdf1ad884da6bc69096bb3413b5b1100559
  show_ref_link: true
  title: Using the Output Embedding to Improve Language Models
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-improved-learning-through-augmenting-the-loss
  numCitedBy: 3
  pid: 5762b7deff7e95febe193196d548379ff34b34f1
  show_ref_link: false
  title: Improved Learning through Augmenting the Loss
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-glove-global-vectors-for-word-representation
  numCitedBy: 22852
  pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  show_ref_link: true
  title: GloVe - Global Vectors for Word Representation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-character-aware-neural-language-models
  numCitedBy: 1434
  pid: 891ce1687e2befddd19f54e4eef1d3f39c8dbaf7
  show_ref_link: true
  title: Character-Aware Neural Language Models
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-pointer-sentinel-mixture-models
  numCitedBy: 1053
  pid: efbd381493bb9636f489b965a2034d529cd56bcd
  show_ref_link: true
  title: Pointer Sentinel Mixture Models
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2000-a-neural-probabilistic-language-model
  numCitedBy: 6054
  pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  show_ref_link: false
  title: A Neural Probabilistic Language Model
  year: 2000
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank
  numCitedBy: 5431
  pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  show_ref_link: true
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-lstm-gru-highway-and-a-bit-of-attention-an-empirical-overview-for-language-modeling-in-speech-recognition
  numCitedBy: 69
  pid: 49899bd9e5a7f59aa14e6d21ed501e3c3acd5852
  show_ref_link: false
  title: LSTM, GRU, Highway and a Bit of Attention - An Empirical Overview for Language Modeling in Speech Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2010-recurrent-neural-network-based-language-model
  numCitedBy: 4935
  pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  show_ref_link: true
  title: Recurrent neural network based language model
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-abstractive-text-summarization-using-sequence-to-sequence-rnns-and-beyond
  numCitedBy: 1581
  pid: f37076f426023241f19cdc2fb0a0fd733a6fa7fa
  show_ref_link: true
  title: Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-recurrent-highway-networks
  numCitedBy: 351
  pid: 7dba53e72c182e25e98e8f73a99d75ff69dda0c2
  show_ref_link: true
  title: Recurrent Highway Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-distributed-representations-of-words-and-phrases-and-their-compositionality
  numCitedBy: 26281
  pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  show_ref_link: true
  title: Distributed Representations of Words and Phrases and their Compositionality
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-multi-way-multilingual-neural-machine-translation-with-a-shared-attention-mechanism
  numCitedBy: 492
  pid: 9ed9bff37ec952134564b3b2a022b7aba9479ff2
  show_ref_link: false
  title: Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-language-modeling-with-sum-product-networks
  numCitedBy: 72
  pid: 2a76c2121eee30af82a24058b4e149f05bcda911
  show_ref_link: false
  title: Language modeling with sum-product networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2007-three-new-graphical-models-for-statistical-language-modelling
  numCitedBy: 609
  pid: bd7d93193aad6c4b71cc8942e808753019e87706
  show_ref_link: false
  title: Three new graphical models for statistical language modelling
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-a-neural-attention-model-for-abstractive-sentence-summarization
  numCitedBy: 2130
  pid: 5082a1a13daea5c7026706738f8528391a1e6d59
  show_ref_link: true
  title: A Neural Attention Model for Abstractive Sentence Summarization
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-distilling-the-knowledge-in-a-neural-network
  numCitedBy: 8901
  pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  show_ref_link: true
  title: Distilling the Knowledge in a Neural Network
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks
  numCitedBy: 1320
  pid: 0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652
  show_ref_link: true
  title: A Theoretically Grounded Application of Dropout in Recurrent Neural Networks
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-on-the-properties-of-neural-machine-translation-encoder-decoder-approaches
  numCitedBy: 4177
  pid: 1eb09fecd75eb27825dce4f964b97f4f5cc399d7
  show_ref_link: true
  title: On the Properties of Neural Machine Translation - Encoder-Decoder Approaches
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-recurrent-neural-network-regularization
  numCitedBy: 1997
  pid: f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97
  show_ref_link: true
  title: Recurrent Neural Network Regularization
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-how-to-construct-deep-recurrent-neural-networks
  numCitedBy: 800
  pid: 533ee188324b833e059cb59b654e6160776d5812
  show_ref_link: false
  title: How to Construct Deep Recurrent Neural Networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 1993-building-a-large-annotated-corpus-of-english-the-penn-treebank
  numCitedBy: 8207
  pid: 0b44fcbeea9415d400c5f5789d6b892b6f98daff
  show_ref_link: false
  title: Building a Large Annotated Corpus of English - The Penn Treebank
  year: 1993
- fieldsOfStudy:
  - Computer Science
  meta_key: 1997-long-short-term-memory
  numCitedBy: 52390
  pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  show_ref_link: true
  title: Long Short-Term Memory
  year: 1997
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-learning-with-a-wasserstein-loss
  numCitedBy: 390
  pid: ae23eda2faddd824480de2d90638795f797cc66e
  show_ref_link: false
  title: Learning with a Wasserstein Loss
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-on-the-difficulty-of-training-recurrent-neural-networks
  numCitedBy: 3849
  pid: 84069287da0a6b488b8c933f3cb5be759cb6237e
  show_ref_link: true
  title: On the difficulty of training recurrent neural networks
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-published-as-a-conference-paper-at-iclr-2018-s-imulating-a-ction-d-ynamics-with-n-eural-p-rocess-n-etworks
  numCitedBy: 156
  pid: bcd857d75841aa3e92cd4284a8818aba9f6c0c3f
  show_ref_link: true
  title: Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-under-review-as-a-conference-paper-at-iclr-2017-delving-into-transferable-adversarial-ex-amples-and-black-box-attacks
  numCitedBy: 488
  pid: 94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f
  show_ref_link: true
  title: Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks
  year: 2016
- fieldsOfStudy:
  - Mathematics
  meta_key: 2007-numerical-methods-for-computing-angles-between-linear-subspaces
  numCitedBy: 597
  pid: bcf377585fa0751b8bb983ccc7cf0866826eebec
  show_ref_link: false
  title: Numerical methods for computing angles between linear subspaces
  year: 2007
- fieldsOfStudy: []
  meta_key: 1891-bulletin-de-la-société-mathématique-de-france
  numCitedBy: 147
  pid: e6647feeaafa97f2b888b906232bcaed38c5bd0d
  show_ref_link: false
  title: Bulletin de la Société Mathématique de France
  year: 1891
- fieldsOfStudy:
  - Psychology
  meta_key: 1994-advances-in-neural-information-processing
  numCitedBy: 144
  pid: 412b11a5552f4afbbed98c37fdadbf20d2e5de75
  show_ref_link: false
  title: Advances in Neural Information Processing
  year: 1994
slug: Tying-Word-Vectors-and-Word-Classifiers:-A-Loss-for-Inan-Khosravi
title: Tying Word Vectors and Word Classifiers - A Loss Framework for Language Modeling
url: https://www.semanticscholar.org/paper/Tying-Word-Vectors-and-Word-Classifiers:-A-Loss-for-Inan-Khosravi/424aef7340ee618132cc3314669400e23ad910ba?sort=total-citations
venue: ICLR
year: 2017
