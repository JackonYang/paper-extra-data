authors:
- Han Cai
- Chuang Gan
- Song Han
badges:
- id: OPEN_ACCESS
corpusId: 201666112
fieldsOfStudy:
- Computer Science
meta_key: 2020-once-for-all-train-one-network-and-specialize-it-for-efficient-deployment
numCitedBy: 512
numCiting: 51
paperAbstract: We address the challenging problem of efficient inference across many devices and resource constraints, especially on edge devices. Conventional approaches either manually design or use neural architecture search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing $CO_2$ emission as much as 5 cars' lifetime) thus unscalable. In this work, we propose to train a once-for-all (OFA) network that supports diverse architectural settings by decoupling training and search, to reduce the cost. We can quickly get a specialized sub-network by selecting from the OFA network without additional training. To efficiently train OFA networks, we also propose a novel progressive shrinking algorithm, a generalized pruning method that reduces the model size across many more dimensions than pruning (depth, width, kernel size, and resolution). It can obtain a surprisingly large number of sub-networks ($> 10^{19}$) that can fit different hardware platforms and latency constraints while maintaining the same level of accuracy as training independently. On diverse edge devices, OFA consistently outperforms state-of-the-art (SOTA) NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and $CO_2$ emission. In particular, OFA achieves a new SOTA 80.0% ImageNet top-1 accuracy under the mobile setting ($<$600M MACs). OFA is the winning solution for the 3rd Low Power Computer Vision Challenge (LPCVC), DSP classification track and the 4th LPCVC, both classification track and detection track. Code and 50 pre-trained models (for many devices & many latency constraints) are released at this https URL.
ref_count: 51
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-fbnet-hardware-aware-efficient-convnet-design-via-differentiable-neural-architecture-search
  numCitedBy: 731
  pid: 45532bffbfbb5553da0b2d0844e95a1b37e59147
  show_ref_link: true
  title: FBNet - Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-mnasnet-platform-aware-neural-architecture-search-for-mobile
  numCitedBy: 1613
  pid: 693c97ecedb0a84539b7162c95e89fa3cd84ca73
  show_ref_link: true
  title: MnasNet - Platform-Aware Neural Architecture Search for Mobile
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-autoslim-towards-one-shot-architecture-search-for-channel-numbers
  numCitedBy: 108
  pid: fdaf68d310a0dd6a83c7753cb1bf209d2f1d4af5
  show_ref_link: false
  title: AutoSlim - Towards One-Shot Architecture Search for Channel Numbers
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-proxylessnas-direct-neural-architecture-search-on-target-task-and-hardware
  numCitedBy: 1117
  pid: dc8b789446416383bfafe9b1c504c4a2b17e68d1
  show_ref_link: true
  title: ProxylessNAS - Direct Neural Architecture Search on Target Task and Hardware
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-efficient-architecture-search-by-network-transformation
  numCitedBy: 422
  pid: 84e65a5bdb735d62eef4f72c2f01af354b2285ba
  show_ref_link: true
  title: Efficient Architecture Search by Network Transformation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-single-path-one-shot-neural-architecture-search-with-uniform-sampling
  numCitedBy: 464
  pid: 79e523beb1e1411a241edde0464b07c2ebc231d1
  show_ref_link: true
  title: Single Path One-Shot Neural Architecture Search with Uniform Sampling
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-learning-both-weights-and-connections-for-efficient-neural-network
  numCitedBy: 4076
  pid: 1ff9a37d766e3a4f39757f5e1b235a42dacf18ff
  show_ref_link: true
  title: Learning both Weights and Connections for Efficient Neural Network
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-multi-scale-dense-networks-for-resource-efficient-image-classification
  numCitedBy: 402
  pid: 125ccd810f43f1cba83c6681836d000f83d1886d
  show_ref_link: false
  title: Multi-Scale Dense Networks for Resource Efficient Image Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-slimmable-neural-networks
  numCitedBy: 249
  pid: 120ffccea4787b88f78b55b9302891ff96cb4228
  show_ref_link: false
  title: Slimmable Neural Networks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-accuracy-vs-efficiency-achieving-both-through-fpga-implementation-aware-neural-architecture-search
  numCitedBy: 82
  pid: fb2040b1be23a625ebb6428431e55f49f0c2c978
  show_ref_link: false
  title: Accuracy vs. Efficiency - Achieving Both through FPGA-Implementation Aware Neural Architecture Search
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-amc-automl-for-model-compression-and-acceleration-on-mobile-devices
  numCitedBy: 843
  pid: 1717255b6aea01fe956cef998abbc3c399b5d7cf
  show_ref_link: true
  title: AMC - AutoML for Model Compression and Acceleration on Mobile Devices
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-efficientnet-rethinking-model-scaling-for-convolutional-neural-networks
  numCitedBy: 5194
  pid: 4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9
  show_ref_link: false
  title: EfficientNet - Rethinking Model Scaling for Convolutional Neural Networks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-path-level-network-transformation-for-efficient-architecture-search
  numCitedBy: 155
  pid: dcc808993310a8a64fdd5efa9e46d0022ff12c27
  show_ref_link: false
  title: Path-Level Network Transformation for Efficient Architecture Search
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-stochastic-downsampling-for-cost-adjustable-inference-and-improved-regularization-in-convolutional-networks
  numCitedBy: 19
  pid: 9784bdcb1401301166869969f468dfbe45aad68d
  show_ref_link: false
  title: Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-runtime-neural-pruning
  numCitedBy: 299
  pid: 88cd4209db62a34d9cba0b9cbe9d45d1e57d21e5
  show_ref_link: true
  title: Runtime Neural Pruning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-learning-efficient-convolutional-networks-through-network-slimming
  numCitedBy: 1257
  pid: 90a16f34d109b63d95ab4da2d491cbe3a1c8b656
  show_ref_link: true
  title: Learning Efficient Convolutional Networks through Network Slimming
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-blockdrop-dynamic-inference-paths-in-residual-networks
  numCitedBy: 284
  pid: e16cfe727e27be27115d0f842375c46e7e3f384b
  show_ref_link: false
  title: BlockDrop - Dynamic Inference Paths in Residual Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-squeezenet-alexnet-level-accuracy-with-50x-fewer-parameters-and-1mb-model-size
  numCitedBy: 4092
  pid: 969fbdcd0717bec06228053788c2ff78bbb4daac
  show_ref_link: true
  title: SqueezeNet - AlexNet-level accuracy with 50x fewer parameters and <1MB model size
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-n2n-learning-network-to-network-compression-via-policy-gradient-reinforcement-learning
  numCitedBy: 127
  pid: 92d621a603cda8c32214d70953e180fe5a442f3e
  show_ref_link: false
  title: N2N Learning - Network to Network Compression via Policy Gradient Reinforcement Learning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-deep-compression-compressing-deep-neural-network-with-pruning-trained-quantization-and-huffman-coding
  numCitedBy: 5732
  pid: 642d0f49b7826adcf986616f4af77e736229990f
  show_ref_link: true
  title: Deep Compression - Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations
  numCitedBy: 2134
  pid: a5733ff08daff727af834345b9cfff1d0aa109ec
  show_ref_link: true
  title: BinaryConnect - Training Deep Neural Networks with binary weights during propagations
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-densely-connected-convolutional-networks
  numCitedBy: 19204
  pid: 5694e46284460a648fe29117cbc55f6c9be3fa3c
  show_ref_link: true
  title: Densely Connected Convolutional Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-searching-for-mobilenetv3
  numCitedBy: 1614
  pid: 83d074cc5051ade0c08d66180e4a04d2c112fa97
  show_ref_link: true
  title: Searching for MobileNetV3
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-mobilenetv2-inverted-residuals-and-linear-bottlenecks
  numCitedBy: 7406
  pid: dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4
  show_ref_link: true
  title: MobileNetV2 - Inverted Residuals and Linear Bottlenecks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-trained-ternary-quantization
  numCitedBy: 801
  pid: d418295cd3027c43eccc5592ae5b8303ba8192be
  show_ref_link: true
  title: Trained Ternary Quantization
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-dynamic-deep-neural-networks-optimizing-accuracy-efficiency-trade-offs-by-selective-execution
  numCitedBy: 132
  pid: adec3702d810f1dfd0e5727406b16713be0a476f
  show_ref_link: false
  title: Dynamic Deep Neural Networks - Optimizing Accuracy-Efficiency Trade-offs by Selective Execution
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-hardware-software-co-exploration-of-neural-architectures
  numCitedBy: 61
  pid: 58beee332c449b7a9471cdacf6118f33aac97c68
  show_ref_link: false
  title: Hardware/Software Co-Exploration of Neural Architectures
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-skipnet-learning-dynamic-routing-in-convolutional-networks
  numCitedBy: 336
  pid: f37ea0b173dd0403a5028c12746082d31dff60bb
  show_ref_link: false
  title: SkipNet - Learning Dynamic Routing in Convolutional Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design
  numCitedBy: 1910
  pid: c02b909a514af6b9255315e2d50112845ca5ed0e
  show_ref_link: true
  title: ShuffleNet V2 - Practical Guidelines for Efficient CNN Architecture Design
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-learning-transferable-architectures-for-scalable-image-recognition
  numCitedBy: 3538
  pid: d0611891b9e8a7c5731146097b6f201578f47b2f
  show_ref_link: true
  title: Learning Transferable Architectures for Scalable Image Recognition
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-searching-for-activation-functions
  numCitedBy: 1490
  pid: c8c4ab59ac29973a00df4e5c8df3773a3c59995a
  show_ref_link: false
  title: Searching for Activation Functions
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-neural-architecture-search-with-reinforcement-learning
  numCitedBy: 3482
  pid: 67d968c7450878190e45ac7886746de867bf673d
  show_ref_link: true
  title: Neural Architecture Search with Reinforcement Learning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices
  numCitedBy: 3251
  pid: 9da734397acd7ff7c557960c62fb1b400b27bd89
  show_ref_link: true
  title: ShuffleNet - An Extremely Efficient Convolutional Neural Network for Mobile Devices
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-distilling-the-knowledge-in-a-neural-network
  numCitedBy: 8901
  pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  show_ref_link: true
  title: Distilling the Knowledge in a Neural Network
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications
  numCitedBy: 10323
  pid: 3647d6d0f151dc05626449ee09cc7bce55be497e
  show_ref_link: true
  title: MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-energy-and-policy-considerations-for-deep-learning-in-nlp
  numCitedBy: 1191
  pid: d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea
  show_ref_link: false
  title: Energy and Policy Considerations for Deep Learning in NLP
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-universally-slimmable-networks-and-improved-training-techniques
  numCitedBy: 184
  pid: 450a99659e083f5ac2f0fef9abbd9336b3470c3b
  show_ref_link: false
  title: Universally Slimmable Networks and Improved Training Techniques
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-squeeze-and-excitation-networks
  numCitedBy: 7692
  pid: df67d46e78aae0d2fccfb6212d101a342259c01b
  show_ref_link: true
  title: Squeeze-and-Excitation Networks
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-deep-residual-learning-for-image-recognition
  numCitedBy: 97653
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-regularized-evolution-for-image-classifier-architecture-search
  numCitedBy: 1843
  pid: 50bdda28de3dcf82a0e10f9ec13eea248b19edb5
  show_ref_link: true
  title: Regularized Evolution for Image Classifier Architecture Search
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-swish-a-self-gated-activation-function
  numCitedBy: 374
  pid: 4f57f486adea0bf95c252620a4e8af39232ef8bc
  show_ref_link: false
  title: Swish - a Self-Gated Activation Function
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-progressive-neural-architecture-search
  numCitedBy: 1377
  pid: 5f79398057bf0bbda9ff50067bc1f2950c2a2266
  show_ref_link: true
  title: Progressive Neural Architecture Search
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-darts-differentiable-architecture-search
  numCitedBy: 2237
  pid: c1f457e31b611da727f9aef76c283a18157dfa83
  show_ref_link: true
  title: DARTS - Differentiable Architecture Search
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-fpga-dnn-co-design-an-efficient-design-methodology-for-1ot-intelligence-on-the-edge
  numCitedBy: 99
  pid: 3083e13c9bacb93d51e9bacb1023fc30fa68046d
  show_ref_link: false
  title: FPGA/DNN Co-Design - An Efficient Design Methodology for 1oT Intelligence on the Edge
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-superposition-of-many-models-into-one
  numCitedBy: 61
  pid: 48f8882739d9f22f56016d133b5688e082db0d08
  show_ref_link: false
  title: Superposition of many models into one
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2009-imagenet-a-large-scale-hierarchical-image-database
  numCitedBy: 28266
  pid: d2c733e34d48784a37d717fe43d9e93277a8c53e
  show_ref_link: true
  title: ImageNet - A large-scale hierarchical image database
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-sgdr-stochastic-gradient-descent-with-warm-restarts
  numCitedBy: 2822
  pid: b022f2a277a4bf5f42382e86e4380b96340b9e86
  show_ref_link: true
  title: SGDR - Stochastic Gradient Descent with Warm Restarts
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2009-roofline-an-insightful-visual-performance-model-for-multicore-architectures
  numCitedBy: 1897
  pid: 092217c2267f6e0673590aa151d811e579ff7760
  show_ref_link: false
  title: Roofline - an insightful visual performance model for multicore architectures
  year: 2009
- fieldsOfStudy: []
  meta_key: 2021-l
  numCitedBy: 29765
  pid: cbe020b715b548694bad73e49c5d72854670d6e7
  show_ref_link: false
  title: "\u2018L'"
  year: 2021
slug: Once-for-All:-Train-One-Network-and-Specialize-it-Cai-Gan
title: Once for All - Train One Network and Specialize it for Efficient Deployment
url: https://www.semanticscholar.org/paper/Once-for-All:-Train-One-Network-and-Specialize-it-Cai-Gan/7823292e5c4b05c47af91ab6ddf671a0da709e82?sort=total-citations
venue: ICLR
year: 2020
