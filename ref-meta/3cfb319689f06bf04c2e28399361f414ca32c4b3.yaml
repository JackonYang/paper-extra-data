authors:
- Colin Raffel
- Noam M. Shazeer
- Adam Roberts
- Katherine Lee
- Sharan Narang
- Michael Matena
- Yanqi Zhou
- Wei Li
- Peter J. Liu
badges:
- id: OPEN_ACCESS
corpusId: 204838007
fieldsOfStudy:
- Computer Science
meta_key: 2020-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer
numCitedBy: 3907
numCiting: 139
paperAbstract: Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.
ref_count: 139
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-universal-language-model-fine-tuning-for-text-classification
  numCitedBy: 2283
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  show_ref_link: true
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-structbert-incorporating-language-structures-into-pre-training-for-deep-language-understanding
  numCitedBy: 143
  pid: d56c1fc337fb07ec004dc846f80582c327af717c
  show_ref_link: false
  title: StructBERT - Incorporating Language Structures into Pre-training for Deep Language Understanding
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-transfer-learning-in-natural-language-processing
  numCitedBy: 205
  pid: 157a7ae44613a1fcf34e2be8c1e19a4f6e3c50e3
  show_ref_link: false
  title: Transfer Learning in Natural Language Processing
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-language-models-are-unsupervised-multitask-learners
  numCitedBy: 6429
  pid: 9405cc0d6169988371b2755e573cc28650d14dfe
  show_ref_link: true
  title: Language Models are Unsupervised Multitask Learners
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-unified-language-model-pre-training-for-natural-language-understanding-and-generation
  numCitedBy: 743
  pid: 1c71771c701aadfd72c5866170a9f5d71464bb88
  show_ref_link: true
  title: Unified Language Model Pre-training for Natural Language Understanding and Generation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-improving-language-understanding-by-generative-pre-training
  numCitedBy: 3591
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  show_ref_link: true
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-multi-task-deep-neural-networks-for-natural-language-understanding
  numCitedBy: 741
  pid: 658721bc13b0fa97366d38c05a96bf0a9f4bb0ac
  show_ref_link: true
  title: Multi-Task Deep Neural Networks for Natural Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding
  numCitedBy: 2690
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  show_ref_link: true
  title: GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-unsupervised-pretraining-for-sequence-to-sequence-learning
  numCitedBy: 249
  pid: 85f94d8098322f8130512b4c6c4627548ce4a6cc
  show_ref_link: false
  title: Unsupervised Pretraining for Sequence to Sequence Learning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-learning-general-purpose-distributed-sentence-representations-via-large-scale-multi-task-learning
  numCitedBy: 278
  pid: afc2850945a871e72c245818f9bc141bd659b453
  show_ref_link: false
  title: Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-scibert-a-pretrained-language-model-for-scientific-text
  numCitedBy: 1043
  pid: 5e98fe2163640da8ab9695b9ee9c433bb30f5353
  show_ref_link: false
  title: SciBERT - A Pretrained Language Model for Scientific Text
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-mass-masked-sequence-to-sequence-pre-training-for-language-generation
  numCitedBy: 609
  pid: 145b8b5d99a2beba6029418ca043585b90138d12
  show_ref_link: false
  title: MASS - Masked Sequence to Sequence Pre-training for Language Generation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-a-simple-method-for-commonsense-reasoning
  numCitedBy: 244
  pid: d7b6753a2d4a2b286c396854063bde3a91b75535
  show_ref_link: false
  title: A Simple Method for Commonsense Reasoning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-distilbert-a-distilled-version-of-bert-smaller-faster-cheaper-and-lighter
  numCitedBy: 2186
  pid: a54b56af24bb4873ed0163b77df63b92bd018ddc
  show_ref_link: false
  title: DistilBERT, a distilled version of BERT - smaller, faster, cheaper and lighter
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-parameter-efficient-transfer-learning-for-nlp
  numCitedBy: 561
  pid: 29ddc1f43f28af7c846515e32cc167bc66886d0c
  show_ref_link: false
  title: Parameter-Efficient Transfer Learning for NLP
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-sentence-encoders-on-stilts-supplementary-training-on-intermediate-labeled-data-tasks
  numCitedBy: 271
  pid: b47381e04739ea3f392ba6c8faaf64105493c196
  show_ref_link: false
  title: Sentence Encoders on STILTs - Supplementary Training on Intermediate Labeled-data Tasks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-cross-lingual-language-model-pretraining
  numCitedBy: 1539
  pid: ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc
  show_ref_link: true
  title: Cross-lingual Language Model Pretraining
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-tinybert-distilling-bert-for-natural-language-understanding
  numCitedBy: 642
  pid: 0cbf97173391b0430140117027edcaf1a37968c7
  show_ref_link: false
  title: TinyBERT - Distilling BERT for Natural Language Understanding
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-sequence-to-sequence-learning-with-neural-networks
  numCitedBy: 14964
  pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  show_ref_link: true
  title: Sequence to Sequence Learning with Neural Networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data
  numCitedBy: 1528
  pid: ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c
  show_ref_link: true
  title: Supervised Learning of Universal Sentence Representations from Natural Language Inference Data
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-can-you-tell-me-how-to-get-past-sesame-street-sentence-level-pretraining-beyond-language-modeling
  numCitedBy: 72
  pid: 06a1bf4a7333bbc78dbd7470666b33bd9e26882b
  show_ref_link: false
  title: Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 34640
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-the-bottom-up-evolution-of-representations-in-the-transformer-a-study-with-machine-translation-and-language-modeling-objectives
  numCitedBy: 91
  pid: 112fd54ee193237b24f2ce7fce79e399609a29c5
  show_ref_link: false
  title: The Bottom-up Evolution of Representations in the Transformer - A Study with Machine Translation and Language Modeling Objectives
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-simple-scalable-adaptation-for-neural-machine-translation
  numCitedBy: 152
  pid: 48530f3d6425f2f150f07ccdd61ba951951a0a7d
  show_ref_link: false
  title: Simple, Scalable Adaptation for Neural Machine Translation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-get-to-the-point-summarization-with-pointer-generator-networks
  numCitedBy: 2501
  pid: 668db48c6a79826456341680ee1175dfc4cced71
  show_ref_link: false
  title: Get To The Point - Summarization with Pointer-Generator Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-boolq-exploring-the-surprising-difficulty-of-natural-yes-no-questions
  numCitedBy: 235
  pid: 9770fff7379a7ab9006b48939462354dda9a2053
  show_ref_link: false
  title: BoolQ - Exploring the Surprising Difficulty of Natural Yes/No Questions
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-exploring-the-limits-of-language-modeling
  numCitedBy: 955
  pid: 2f2d8f8072e5cc9b296fad551f65f183bdbff7aa
  show_ref_link: true
  title: Exploring the Limits of Language Modeling
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-summae-zero-shot-abstractive-text-summarization-using-length-agnostic-auto-encoders
  numCitedBy: 10
  pid: 1f6905b238cc99a7657c3e5e16a035eae913ea3f
  show_ref_link: false
  title: SummAE - Zero-Shot Abstractive Text Summarization using Length-Agnostic Auto-Encoders
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-a-deep-reinforced-model-for-abstractive-summarization
  numCitedBy: 1076
  pid: 032274e57f7d8b456bd255fe76b909b2c1d7458e
  show_ref_link: false
  title: A Deep Reinforced Model for Abstractive Summarization
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-skip-thought-vectors
  numCitedBy: 1934
  pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  show_ref_link: true
  title: Skip-Thought Vectors
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-abstractive-text-summarization-using-sequence-to-sequence-rnns-and-beyond
  numCitedBy: 1569
  pid: f37076f426023241f19cdc2fb0a0fd733a6fa7fa
  show_ref_link: true
  title: Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-massively-multilingual-neural-machine-translation-in-the-wild-findings-and-challenges
  numCitedBy: 219
  pid: c17985a669522e7e85ae3d34754c7df49c7187d1
  show_ref_link: false
  title: Massively Multilingual Neural Machine Translation in the Wild - Findings and Challenges
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-unifying-question-answering-and-text-classification-via-span-extraction
  numCitedBy: 16
  pid: 9e10e2cae05b2906330eb7dde2f27042966413b1
  show_ref_link: false
  title: Unifying Question Answering and Text Classification via Span Extraction
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-albert-a-lite-bert-for-self-supervised-learning-of-language-representations
  numCitedBy: 2773
  pid: 7a064df1aeada7e69e5173f7d4c8606f4470365b
  show_ref_link: true
  title: ALBERT - A Lite BERT for Self-supervised Learning of Language Representations
  year: 2020
- fieldsOfStudy:
  - Computer Science
  - Psychology
  meta_key: 2017-semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation
  numCitedBy: 950
  pid: a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096
  show_ref_link: true
  title: SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-understanding-back-translation-at-scale
  numCitedBy: 682
  pid: 807370352540f171685998aec7a5701f7110f147
  show_ref_link: false
  title: Understanding Back-Translation at Scale
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank
  numCitedBy: 5397
  pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  show_ref_link: true
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-semi-supervised-sequence-learning
  numCitedBy: 888
  pid: 4aa9f5150b46320f534de4747a2dd0cd7f3fe292
  show_ref_link: false
  title: Semi-supervised Sequence Learning
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-qanet-combining-local-convolution-with-global-self-attention-for-reading-comprehension
  numCitedBy: 805
  pid: 8c1b00128e74f1cd92aede3959690615695d5101
  show_ref_link: false
  title: QANet - Combining Local Convolution with Global Self-Attention for Reading Comprehension
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-representation-learning-using-multi-task-deep-neural-networks-for-semantic-classification-and-information-retrieval
  numCitedBy: 366
  pid: c3b8367a80181e28c95630b9b63060d895de08ff
  show_ref_link: false
  title: Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-to-tune-or-not-to-tune-adapting-pretrained-representations-to-diverse-tasks
  numCitedBy: 273
  pid: 8659bf379ca8756755125a487c43cfe8611ce842
  show_ref_link: false
  title: To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-deep-contextualized-word-representations
  numCitedBy: 8062
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-ctrl-a-conditional-transformer-language-model-for-controllable-generation
  numCitedBy: 501
  pid: 75acc731bdd2b626edc74672a30da3bc51010ae8
  show_ref_link: false
  title: CTRL - A Conditional Transformer Language Model for Controllable Generation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-attention-is-all-you-need
  numCitedBy: 35966
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation
  numCitedBy: 4687
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  show_ref_link: true
  title: Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-snorkel-metal-weak-supervision-for-multi-task-learning
  numCitedBy: 34
  pid: cba294bc7e2f2afa919e2ff19ff46390be892804
  show_ref_link: false
  title: Snorkel MeTaL - Weak Supervision for Multi-Task Learning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-wic-10-000-example-pairs-for-evaluating-context-sensitive-representations
  numCitedBy: 30
  pid: 84a6d47676c2d2c1414d3893d09e47d33906fb1c
  show_ref_link: false
  title: WiC - 10, 000 Example Pairs for Evaluating Context-Sensitive Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-xlnet-generalized-autoregressive-pretraining-for-language-understanding
  numCitedBy: 4296
  pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  show_ref_link: true
  title: XLNet - Generalized Autoregressive Pretraining for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference
  numCitedBy: 2075
  pid: 5ded2b8c64491b4a67f6d39ce473d4b9347a672e
  show_ref_link: true
  title: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-a-convolutional-neural-network-for-modelling-sentences
  numCitedBy: 3000
  pid: 27725a2d2a8cee9bf9fffc6c2167017103aba0fa
  show_ref_link: true
  title: A Convolutional Neural Network for Modelling Sentences
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-exploring-the-limits-of-weakly-supervised-pretraining
  numCitedBy: 849
  pid: 0f885fd46064d271d4404cf9bb3d758e1a6f8d55
  show_ref_link: false
  title: Exploring the Limits of Weakly Supervised Pretraining
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-an-efficient-framework-for-learning-sentence-representations
  numCitedBy: 350
  pid: bc1d609520290e0460c49b685675eb5a57fa5935
  show_ref_link: false
  title: An efficient framework for learning sentence representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-learning-distributed-representations-of-sentences-from-unlabelled-data
  numCitedBy: 459
  pid: 26e743d5bd465f49b9538deaf116c15e61b7951f
  show_ref_link: true
  title: Learning Distributed Representations of Sentences from Unlabelled Data
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-sentencepiece-a-simple-and-language-independent-subword-tokenizer-and-detokenizer-for-neural-text-processing
  numCitedBy: 1550
  pid: b5246fa284f86b544a7c31f050b3bd0defd053fd
  show_ref_link: false
  title: SentencePiece - A simple and language independent subword tokenizer and detokenizer for Neural Text Processing
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-looking-beyond-the-surface-a-challenge-set-for-reading-comprehension-over-multiple-sentences
  numCitedBy: 257
  pid: 99ad0533f84c110da2d0713d5798e6e14080b159
  show_ref_link: false
  title: Looking Beyond the Surface - A Challenge Set for Reading Comprehension over Multiple Sentences
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-learning-word-vectors-for-157-languages
  numCitedBy: 903
  pid: 94a178bc81d045bbc7ff6bb83738c2491c3c9985
  show_ref_link: false
  title: Learning Word Vectors for 157 Languages
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-teaching-machines-to-read-and-comprehend
  numCitedBy: 2456
  pid: d1505c6123c102e53eb19dff312cb25cea840b72
  show_ref_link: true
  title: Teaching Machines to Read and Comprehend
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-cloze-driven-pretraining-of-self-attention-networks
  numCitedBy: 153
  pid: 9f1c5777a193b2c3bb2b25e248a156348e5ba56d
  show_ref_link: false
  title: Cloze-driven Pretraining of Self-attention Networks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-squad-100-000-questions-for-machine-comprehension-of-text
  numCitedBy: 4308
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  show_ref_link: true
  title: SQuAD - 100,000+ Questions for Machine Comprehension of Text
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-triviaqa-a-large-scale-distantly-supervised-challenge-dataset-for-reading-comprehension
  numCitedBy: 900
  pid: f010affab57b5fcf1cd6be23df79d8ec98c7289c
  show_ref_link: true
  title: TriviaQA - A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-outrageously-large-neural-networks-the-sparsely-gated-mixture-of-experts-layer
  numCitedBy: 871
  pid: 510e26733aaff585d65701b9f1be7ca9d5afc586
  show_ref_link: true
  title: Outrageously Large Neural Networks - The Sparsely-Gated Mixture-of-Experts Layer
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-neural-machine-translation-by-jointly-learning-to-align-and-translate
  numCitedBy: 19461
  pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  show_ref_link: true
  title: Neural Machine Translation by Jointly Learning to Align and Translate
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-neural-machine-translation-of-rare-words-with-subword-units
  numCitedBy: 4834
  pid: 1af68821518f03568f913ab03fc02080247a27ff
  show_ref_link: true
  title: Neural Machine Translation of Rare Words with Subword Units
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems
  numCitedBy: 838
  pid: d9f6ada77448664b71128bb19df15765336974a6
  show_ref_link: false
  title: SuperGLUE - A Stickier Benchmark for General-Purpose Language Understanding Systems
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-character-level-language-modeling-with-deeper-self-attention
  numCitedBy: 219
  pid: b9de9599d7241459db9213b5cdd7059696f5ef8d
  show_ref_link: true
  title: Character-Level Language Modeling with Deeper Self-Attention
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-fine-tune-bert-for-extractive-summarization
  numCitedBy: 208
  pid: a10a6495723ea8c928680ecdd61714f5750586c3
  show_ref_link: false
  title: Fine-tune BERT for Extractive Summarization
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-a-call-for-clarity-in-reporting-bleu-scores
  numCitedBy: 1134
  pid: b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb
  show_ref_link: false
  title: A Call for Clarity in Reporting BLEU Scores
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-n-gram-counts-and-language-models-from-the-common-crawl
  numCitedBy: 147
  pid: 8e4fb17fff38a7834af5b4eaafcbbde02bf00975
  show_ref_link: false
  title: N-gram Counts and Language Models from the Common Crawl
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-freelb-enhanced-adversarial-training-for-language-understanding
  numCitedBy: 64
  pid: d2038ced371e45aee3651c7a595c4566f4826b9f
  show_ref_link: false
  title: FreeLB - Enhanced Adversarial Training for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-newsqa-a-machine-comprehension-dataset
  numCitedBy: 590
  pid: 3eda43078ae1f4741f09be08c4ecab6229046a5c
  show_ref_link: true
  title: NewsQA - A Machine Comprehension Dataset
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-subword-regularization-improving-neural-network-translation-models-with-multiple-subword-candidates
  numCitedBy: 551
  pid: e73bd7f9bdc262b9b7fb60ca0d5230d3ab0fad5e
  show_ref_link: false
  title: Subword Regularization - Improving Neural Network Translation Models with Multiple Subword Candidates
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-a-surprisingly-robust-trick-for-the-winograd-schema-challenge
  numCitedBy: 81
  pid: c57298fe3faf87f9f24414821b0df7ebb7634320
  show_ref_link: false
  title: A Surprisingly Robust Trick for the Winograd Schema Challenge
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-spanbert-improving-pre-training-by-representing-and-predicting-spans
  numCitedBy: 906
  pid: 81f5810fbbab9b7203b9556f4ce3c741875407bc
  show_ref_link: true
  title: SpanBERT - Improving Pre-training by Representing and Predicting Spans
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-self-attention-with-relative-position-representations
  numCitedBy: 935
  pid: c8efcc854d97dfc2a42b83316a2109f9d166e43f
  show_ref_link: true
  title: Self-Attention with Relative Position Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-generating-sentences-from-a-continuous-space
  numCitedBy: 1754
  pid: d82b55c35c8673774a708353838918346f6c006f
  show_ref_link: false
  title: Generating Sentences from a Continuous Space
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-c4corpus-multilingual-web-size-corpus-with-free-license
  numCitedBy: 27
  pid: 7a684045afae2ccf40338ff07b8fa429bad93a57
  show_ref_link: false
  title: C4Corpus - Multilingual Web-size Corpus with Free License
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-senteval-an-evaluation-toolkit-for-universal-sentence-representations
  numCitedBy: 330
  pid: 7113bd87c3e6f727efae24ee52f20c81358da761
  show_ref_link: false
  title: SentEval - An Evaluation Toolkit for Universal Sentence Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-deep-learning-scaling-is-predictable-empirically
  numCitedBy: 272
  pid: a1c922be467d1c0c64b963e65dae41778b81b2a0
  show_ref_link: false
  title: Deep Learning Scaling is Predictable, Empirically
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-long-short-term-memory-networks-for-machine-reading
  numCitedBy: 771
  pid: 13fe71da009484f240c46f14d9330e932f8de210
  show_ref_link: false
  title: Long Short-Term Memory-Networks for Machine Reading
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-distilling-the-knowledge-in-a-neural-network
  numCitedBy: 8808
  pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  show_ref_link: true
  title: Distilling the Knowledge in a Neural Network
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-glove-global-vectors-for-word-representation
  numCitedBy: 22729
  pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  show_ref_link: true
  title: GloVe - Global Vectors for Word Representation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-findings-of-the-2015-workshop-on-statistical-machine-translation
  numCitedBy: 256
  pid: feb420a4ac7c5719d51480053cd3e8669d5f2062
  show_ref_link: false
  title: Findings of the 2015 Workshop on Statistical Machine Translation
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-a-hybrid-neural-network-model-for-commonsense-reasoning
  numCitedBy: 20
  pid: f5e3990ab9a67f824ef2c28114e2b158d653edca
  show_ref_link: false
  title: A Hybrid Neural Network Model for Commonsense Reasoning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-an-overview-of-multi-task-learning-in-deep-neural-networks
  numCitedBy: 1554
  pid: 6d431f835c06afdea45dff6b24486bf301ebdef0
  show_ref_link: false
  title: An Overview of Multi-Task Learning in Deep Neural Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-what-makes-imagenet-good-for-transfer-learning
  numCitedBy: 447
  pid: 540b5b4919d345e4da3cc4f3e8a7862329bf41a2
  show_ref_link: false
  title: What makes ImageNet good for transfer learning?
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-findings-of-the-2016-conference-on-machine-translation
  numCitedBy: 515
  pid: 1a327709cc53ff9e52454e50a643abf4a0ac92af
  show_ref_link: false
  title: Findings of the 2016 Conference on Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-generating-wikipedia-by-summarizing-long-sequences
  numCitedBy: 462
  pid: 7570afa31c68e24fce1342b7d67c591787219bc1
  show_ref_link: false
  title: Generating Wikipedia by Summarizing Long Sequences
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-dirt-cheap-web-scale-parallel-text-from-the-common-crawl
  numCitedBy: 132
  pid: 31e8337daa0bfd7aa7737cd9383adaaa4275ead0
  show_ref_link: false
  title: Dirt Cheap Web-Scale Parallel Text from the Common Crawl
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-rethinking-imagenet-pre-training
  numCitedBy: 584
  pid: 4152d2c8585f7e3f85d3b3d84036171de104cbd7
  show_ref_link: false
  title: Rethinking ImageNet Pre-Training
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-deep-residual-learning-for-image-recognition
  numCitedBy: 96474
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-distributed-representations-of-words-and-phrases-and-their-compositionality
  numCitedBy: 26176
  pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  show_ref_link: true
  title: Distributed Representations of Words and Phrases and their Compositionality
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-do-better-imagenet-models-transfer-better
  numCitedBy: 669
  pid: 8a8cfa45b4c0d071fbffa091c02670b19c94b693
  show_ref_link: false
  title: Do Better ImageNet Models Transfer Better?
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-findings-of-the-2014-workshop-on-statistical-machine-translation
  numCitedBy: 430
  pid: 5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc
  show_ref_link: false
  title: Findings of the 2014 Workshop on Statistical Machine Translation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-an-overview-of-multi-task-learning
  numCitedBy: 775
  pid: cd49acefc8d51e324aa562e5337e1c2aff067053
  show_ref_link: false
  title: An Overview of Multi-task Learning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting
  numCitedBy: 28300
  pid: 34f25a8704614163c4095b3ee2fc969b60de4698
  show_ref_link: true
  title: Dropout - a simple way to prevent neural networks from overfitting
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-efficient-estimation-of-word-representations-in-vector-space
  numCitedBy: 22047
  pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  show_ref_link: true
  title: Efficient Estimation of Word Representations in Vector Space
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books
  numCitedBy: 1441
  pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  show_ref_link: true
  title: Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2005-automatically-constructing-a-corpus-of-sentential-paraphrases
  numCitedBy: 841
  pid: 475354f10798f110d34792b6d88f31d6d5cb099e
  show_ref_link: false
  title: Automatically Constructing a Corpus of Sentential Paraphrases
  year: 2005
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-defending-against-neural-fake-news
  numCitedBy: 412
  pid: ad7129af0644dbcafa9aa2f111cb76526ea444a1
  show_ref_link: false
  title: Defending Against Neural Fake News
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 1998-multitask-learning
  numCitedBy: 3375
  pid: 47aaeb6dc682162dfe5659c2cad64e5d825ad910
  show_ref_link: false
  title: Multitask Learning
  year: 1998
- fieldsOfStudy:
  - Computer Science
  meta_key: 2012-resolving-complex-cases-of-definite-pronouns-the-winograd-schema-challenge
  numCitedBy: 150
  pid: b0c5f72790cca220541ea4809d1e43b4bdad1124
  show_ref_link: false
  title: Resolving Complex Cases of Definite Pronouns - The Winograd Schema Challenge
  year: 2012
- fieldsOfStudy:
  - Computer Science
  - Linguistics
  meta_key: 2019-neural-network-acceptability-judgments
  numCitedBy: 556
  pid: cb0f3ee1e98faf92429d601cdcd76c69c1e484eb
  show_ref_link: true
  title: Neural Network Acceptability Judgments
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-how-transferable-are-features-in-deep-neural-networks
  numCitedBy: 5810
  pid: 081651b38ff7533550a3adfc1c00da333a8fe86c
  show_ref_link: true
  title: How transferable are features in deep neural networks?
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-music-transformer-generating-music-with-long-term-structure
  numCitedBy: 211
  pid: fb507ada871d1e8c29e376dbf7b7879689aa89f9
  show_ref_link: false
  title: Music Transformer - Generating Music with Long-Term Structure
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-adafactor-adaptive-learning-rates-with-sublinear-memory-cost
  numCitedBy: 307
  pid: 54a13bcc9613dcaa76fb25fbe96572f376cfcca9
  show_ref_link: false
  title: Adafactor - Adaptive Learning Rates with Sublinear Memory Cost
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2005-the-pascal-recognising-textual-entailment-challenge
  numCitedBy: 1774
  pid: de794d50713ea5f91a7c9da3d72041e2f5ef8452
  show_ref_link: false
  title: The PASCAL Recognising Textual Entailment Challenge
  year: 2005
- fieldsOfStudy:
  - Computer Science
  meta_key: 2004-rouge-a-package-for-automatic-evaluation-of-summaries
  numCitedBy: 7019
  pid: 60b05f32c32519a809f21642ef1eb3eaf3848008
  show_ref_link: true
  title: ROUGE - A Package for Automatic Evaluation of Summaries
  year: 2004
- fieldsOfStudy:
  - Computer Science
  meta_key: 2009-imagenet-a-large-scale-hierarchical-image-database
  numCitedBy: 27839
  pid: d2c733e34d48784a37d717fe43d9e93277a8c53e
  show_ref_link: true
  title: ImageNet - A large-scale hierarchical image database
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-learning-and-transferring-mid-level-image-representations-using-convolutional-neural-networks
  numCitedBy: 2750
  pid: c08f5fa876181fc040d76c75fe2433eee3c9b001
  show_ref_link: true
  title: Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2002-bleu-a-method-for-automatic-evaluation-of-machine-translation
  numCitedBy: 16745
  pid: d7da009f457917aa381619facfa5ffae9329a6e9
  show_ref_link: true
  title: Bleu - a Method for Automatic Evaluation of Machine Translation
  year: 2002
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-measuring-the-effects-of-data-parallelism-on-neural-network-training
  numCitedBy: 246
  pid: b2c8e834ac5f7be68b9ca3691d39925036dd74a3
  show_ref_link: false
  title: Measuring the Effects of Data Parallelism on Neural Network Training
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-mesh-tensorflow-deep-learning-for-supercomputers
  numCitedBy: 212
  pid: 2270b8628fd8ca67ae39d277f45bc3c38ac63d5f
  show_ref_link: false
  title: Mesh-TensorFlow - Deep Learning for Supercomputers
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-caffe-convolutional-architecture-for-fast-feature-embedding
  numCitedBy: 13775
  pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  show_ref_link: true
  title: Caffe - Convolutional Architecture for Fast Feature Embedding
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-memory-efficient-adaptive-optimization-for-large-scale-learning
  numCitedBy: 15
  pid: 0a464df731945c16d4d97f77dc6d3f22b8a65bd2
  show_ref_link: false
  title: Memory-Efficient Adaptive Optimization for Large-Scale Learning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-record-bridging-the-gap-between-human-and-machine-commonsense-reading-comprehension
  numCitedBy: 158
  pid: a5b66ee341cb990f7f70a124b5fab3316d3b7e27
  show_ref_link: false
  title: ReCoRD - Bridging the Gap between Human and Machine Commonsense Reading Comprehension
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-gpipe-efficient-training-of-giant-neural-networks-using-pipeline-parallelism
  numCitedBy: 652
  pid: c18663fea10c8a303d045fd2c1f33cacf9b73ca3
  show_ref_link: false
  title: GPipe - Efficient Training of Giant Neural Networks using Pipeline Parallelism
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2013-generating-sequences-with-recurrent-neural-networks
  numCitedBy: 3163
  pid: 89b1f4740ae37fd04f6ac007577bdd34621f0861
  show_ref_link: true
  title: Generating Sequences With Recurrent Neural Networks
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-federated-learning-strategies-for-improving-communication-efficiency
  numCitedBy: 2080
  pid: 7fcb90f68529cbfab49f471b54719ded7528d0ef
  show_ref_link: false
  title: Federated Learning - Strategies for Improving Communication Efficiency
  year: 2016
- fieldsOfStudy:
  - Philosophy
  meta_key: 2019-the-commitmentbank-investigating-projection-in-naturally-occurring-discourse
  numCitedBy: 98
  pid: 39e801ca0dbc69c3697f118e24dac964abb63d4a
  show_ref_link: false
  title: The CommitmentBank - Investigating projection in naturally occurring discourse
  year: 2019
- fieldsOfStudy:
  - Linguistics
  meta_key: 2011-the-winograd-schema-challenge
  numCitedBy: 704
  pid: 128cb6b891aee1b5df099acb48e2efecfcff689f
  show_ref_link: false
  title: The Winograd Schema Challenge
  year: 2011
- fieldsOfStudy:
  - Education
  meta_key: 2018-the-natural-language-decathlon-multitask-learning-as-question-answering
  numCitedBy: 412
  pid: 9784fbf77295860b2e412137b86356d70b25e3c0
  show_ref_link: false
  title: The Natural Language Decathlon - Multitask Learning as Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-imagenet-large-scale-visual-recognition-challenge
  numCitedBy: 25650
  pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  show_ref_link: true
  title: ImageNet Large Scale Visual Recognition Challenge
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-federated-optimization-distributed-optimization-beyond-the-datacenter
  numCitedBy: 383
  pid: 614ec0fe23fe21235126cc5c92ccf5a739a3ae32
  show_ref_link: false
  title: Federated Optimization - Distributed Optimization Beyond the Datacenter
  year: 2015
- fieldsOfStudy:
  - Psychology
  meta_key: 2012-semeval-2012-task-7-choice-of-plausible-alternatives-an-evaluation-of-commonsense-causal-reasoning
  numCitedBy: 278
  pid: fb0b11046474b8f1c810f947f313c7c7229a988f
  show_ref_link: false
  title: SemEval-2012 Task 7 - Choice of Plausible Alternatives - An Evaluation of Commonsense Causal Reasoning
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: 1989-a-learning-algorithm-for-continually-running-fully-recurrent-neural-networks
  numCitedBy: 3844
  pid: ce9a21b93ba29d4145a8ef6bf401e77f261848de
  show_ref_link: false
  title: A Learning Algorithm for Continually Running Fully Recurrent Neural Networks
  year: 1989
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-one-weird-trick-for-parallelizing-convolutional-neural-networks
  numCitedBy: 885
  pid: 80d800dfadbe2e6c7b2367d9229cc82912d55889
  show_ref_link: false
  title: One weird trick for parallelizing convolutional neural networks
  year: 2014
- fieldsOfStudy:
  - Education
  meta_key: 1953-cloze-procedure-a-new-tool-for-measuring-readability
  numCitedBy: 2054
  pid: 766ce989b8b8b984f7a4691fd8c9af4bdb2b74cd
  show_ref_link: false
  title: "\u201CCloze Procedure\u201D - A New Tool for Measuring Readability"
  year: 1953
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-roberta-a-robustly-optimized-bert-pretraining-approach
  numCitedBy: 7556
  pid: 077f8329a7b6fa3b7c877a57b81eb6c18b5f87de
  show_ref_link: true
  title: RoBERTa - A Robustly Optimized BERT Pretraining Approach
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-electra-pre-training-text-encoders-as-discriminators-rather-than-generators
  numCitedBy: 1239
  pid: 756810258e3419af76aff38c895c20343b0602d0
  show_ref_link: false
  title: ELECTRA - Pre-training Text Encoders as Discriminators Rather Than Generators
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-neural-transfer-learning-for-natural-language-processing
  numCitedBy: 145
  pid: 85e3010ff82c07961bc21f63b91a4981fa5123fe
  show_ref_link: false
  title: Neural transfer learning for natural language processing
  year: 2019
- fieldsOfStudy:
  - Physics
  meta_key: 2006-low-field-squid-mri-to-tune-or-not-to-tune
  numCitedBy: 28
  pid: 33b1340b207c49380f87eaae6ef4eef9165a69af
  show_ref_link: false
  title: Low-field SQUID MRI - To tune or not to tune?
  year: 2006
- fieldsOfStudy:
  - Medicine
  meta_key: 1999-a-bitter-lesson
  numCitedBy: 99
  pid: 7bea855e19fd13461590e4f2d44bbf7b807ce3e3
  show_ref_link: false
  title: A bitter lesson.
  year: 1999
slug: Exploring-the-Limits-of-Transfer-Learning-with-a-Raffel-Shazeer
title: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
url: https://www.semanticscholar.org/paper/Exploring-the-Limits-of-Transfer-Learning-with-a-Raffel-Shazeer/3cfb319689f06bf04c2e28399361f414ca32c4b3?sort=total-citations
venue: J. Mach. Learn. Res.
year: 2020
