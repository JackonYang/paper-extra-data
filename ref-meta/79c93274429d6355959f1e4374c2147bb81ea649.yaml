authors:
- Hao Hao Tan
- Mohit Bansal
badges:
- id: OPEN_ACCESS
corpusId: 201103729
fieldsOfStudy:
- Computer Science
meta_key: 2019-lxmert-learning-cross-modality-encoder-representations-from-transformers
numCitedBy: 952
numCiting: 44
paperAbstract: 'Vision-and-language reasoning requires an understanding of visual concepts, language semantics, and, most importantly, the alignment and relationships between these two modalities. We thus propose the LXMERT (Learning Cross-Modality Encoder Representations from Transformers) framework to learn these vision-and-language connections. In LXMERT, we build a large-scale Transformer model that consists of three encoders: an object relationship encoder, a language encoder, and a cross-modality encoder. Next, to endow our model with the capability of connecting vision and language semantics, we pre-train the model with large amounts of image-and-sentence pairs, via five diverse representative pre-training tasks: masked language modeling, masked object prediction (feature regression and label classification), cross-modality matching, and image question answering. These tasks help in learning both intra-modality and cross-modality relationships. After fine-tuning from our pre-trained parameters, our model achieves the state-of-the-art results on two visual question answering datasets (i.e., VQA and GQA). We also show the generalizability of our pre-trained cross-modality model by adapting it to a challenging visual-reasoning task, NLVR2, and improve the previous best result by 22% absolute (54% to 76%). Lastly, we demonstrate detailed ablation studies to prove that both our novel model components and pre-training strategies significantly contribute to our strong results. Code and pre-trained models publicly available at: https://github.com/airsplay/lxmert'
ref_count: 44
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks
  numCitedBy: 1319
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  show_ref_link: true
  title: ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 34640
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-multimodal-unified-attention-networks-for-vision-and-language-interactions
  numCitedBy: 22
  pid: a3d3df29fc98e0d674bf02bab69726795f4c7b78
  show_ref_link: false
  title: Multimodal Unified Attention Networks for Vision-and-Language Interactions
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-videobert-a-joint-model-for-video-and-language-representation-learning
  numCitedBy: 584
  pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  show_ref_link: true
  title: VideoBERT - A Joint Model for Video and Language Representation Learning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-attention-is-all-you-need
  numCitedBy: 35966
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-visual7w-grounded-question-answering-in-images
  numCitedBy: 598
  pid: def584565d05d6a8ba94de6621adab9e301d375d
  show_ref_link: true
  title: Visual7W - Grounded Question Answering in Images
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-multi-modality-latent-interaction-network-for-visual-question-answering
  numCitedBy: 48
  pid: cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6
  show_ref_link: false
  title: Multi-Modality Latent Interaction Network for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-visualbert-a-simple-and-performant-baseline-for-vision-and-language
  numCitedBy: 664
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  show_ref_link: true
  title: VisualBERT - A Simple and Performant Baseline for Vision and Language
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-dynamic-fusion-with-intra-and-inter-modality-attention-flow-for-visual-question-answering
  numCitedBy: 191
  pid: e9b13731027418ed38103d1dfc8a70f6881bc684
  show_ref_link: true
  title: Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-deep-modular-co-attention-networks-for-visual-question-answering
  numCitedBy: 324
  pid: 8a1744da011375d711ed75fc2d160c6fdca2cf89
  show_ref_link: true
  title: Deep Modular Co-Attention Networks for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-exbert-a-visual-analysis-tool-to-explore-learned-representations-in-transformer-models
  numCitedBy: 80
  pid: 327d7e55d64cb34d55bd3a3fe58233c238a312cd
  show_ref_link: false
  title: exBERT - A Visual Analysis Tool to Explore Learned Representations in Transformer Models
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-beyond-bilinear-generalized-multimodal-factorized-high-order-pooling-for-visual-question-answering
  numCitedBy: 267
  pid: 0c0f41d3162e76500d4639557ff4463bd246e395
  show_ref_link: false
  title: Beyond Bilinear - Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering
  numCitedBy: 1178
  pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  show_ref_link: true
  title: Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-bilinear-attention-networks
  numCitedBy: 418
  pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  show_ref_link: true
  title: Bilinear Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations
  numCitedBy: 2810
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  show_ref_link: true
  title: Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-film-visual-reasoning-with-a-general-conditioning-layer
  numCitedBy: 844
  pid: 7cfa5c97164129ce3630511f639040d28db1d4b7
  show_ref_link: true
  title: FiLM - Visual Reasoning with a General Conditioning Layer
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-hierarchical-question-image-co-attention-for-visual-question-answering
  numCitedBy: 1130
  pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  show_ref_link: true
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding
  numCitedBy: 2690
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  show_ref_link: true
  title: GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-cross-lingual-language-model-pretraining
  numCitedBy: 1539
  pid: ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc
  show_ref_link: true
  title: Cross-lingual Language Model Pretraining
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-learning-to-reason-end-to-end-module-networks-for-visual-question-answering
  numCitedBy: 435
  pid: a396a6febdacb84340d139096455e67049ac1e22
  show_ref_link: true
  title: Learning to Reason - End-to-End Module Networks for Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-neural-machine-translation-by-jointly-learning-to-align-and-translate
  numCitedBy: 19455
  pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  show_ref_link: true
  title: Neural Machine Translation by Jointly Learning to Align and Translate
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-gqa-a-new-dataset-for-compositional-question-answering-over-real-world-images
  numCitedBy: 89
  pid: c122fa378a774ba202d418cf71c5c356cf2f902f
  show_ref_link: false
  title: GQA - a new dataset for compositional question answering over real-world images
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-cycle-consistency-for-robust-visual-question-answering
  numCitedBy: 94
  pid: 735a63b58349e07b84c2e31927ce1b1cfaf09980
  show_ref_link: false
  title: Cycle-Consistency for Robust Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention
  numCitedBy: 7306
  pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  show_ref_link: true
  title: Show, Attend and Tell - Neural Image Caption Generation with Visual Attention
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation
  numCitedBy: 4687
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  show_ref_link: true
  title: Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-bidirectional-attention-flow-for-machine-comprehension
  numCitedBy: 1726
  pid: 3a7b63b50c64f4ec3358477790e84cbd6be2a0b4
  show_ref_link: true
  title: Bidirectional Attention Flow for Machine Comprehension
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering
  numCitedBy: 2310
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-vqa-visual-question-answering
  numCitedBy: 2930
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  show_ref_link: true
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-deep-contextualized-word-representations
  numCitedBy: 8062
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-deep-residual-learning-for-image-recognition
  numCitedBy: 96474
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation
  numCitedBy: 17210
  pid: 2f4df08d9072fc2ac181b7fced6a245315ce05c8
  show_ref_link: true
  title: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-a-corpus-for-reasoning-about-natural-language-grounded-in-photographs
  numCitedBy: 214
  pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  show_ref_link: true
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-going-deeper-with-convolutions
  numCitedBy: 29682
  pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  show_ref_link: true
  title: Going deeper with convolutions
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-very-deep-convolutional-networks-for-large-scale-image-recognition
  numCitedBy: 62697
  pid: eb42cf88027de515750f230b23b1a057dc782108
  show_ref_link: true
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-pythia-v0-1-the-winning-entry-to-the-vqa-challenge-2018
  numCitedBy: 142
  pid: 36c3972569a6949ecca90bfa6f8e99883e092845
  show_ref_link: false
  title: Pythia v0.1 - the Winning Entry to the VQA Challenge 2018
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-gated-feedback-recurrent-neural-networks
  numCitedBy: 650
  pid: d14c7e5f5cace4c925abc74c88baa474e9f31a28
  show_ref_link: false
  title: Gated Feedback Recurrent Neural Networks
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks
  numCitedBy: 32899
  pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  show_ref_link: true
  title: Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-adam-a-method-for-stochastic-optimization
  numCitedBy: 90882
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  show_ref_link: true
  title: Adam - A Method for Stochastic Optimization
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-squad-100-000-questions-for-machine-comprehension-of-text
  numCitedBy: 4308
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  show_ref_link: true
  title: SQuAD - 100,000+ Questions for Machine Comprehension of Text
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2014-microsoft-coco-common-objects-in-context
  numCitedBy: 19980
  pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  show_ref_link: true
  title: Microsoft COCO - Common Objects in Context
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: 2009-imagenet-a-large-scale-hierarchical-image-database
  numCitedBy: 27818
  pid: d2c733e34d48784a37d717fe43d9e93277a8c53e
  show_ref_link: true
  title: ImageNet - A large-scale hierarchical image database
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-bridging-nonlinearities-and-stochastic-regularizers-with-gaussian-error-linear-units
  numCitedBy: 292
  pid: 4361e64f2d12d63476fdc88faf72a0f70d9a2ffb
  show_ref_link: true
  title: Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-improving-language-understanding-by-generative-pre-training
  numCitedBy: 3591
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  show_ref_link: true
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
slug: LXMERT:-Learning-Cross-Modality-Encoder-from-Tan-Bansal
title: LXMERT - Learning Cross-Modality Encoder Representations from Transformers
url: https://www.semanticscholar.org/paper/LXMERT:-Learning-Cross-Modality-Encoder-from-Tan-Bansal/79c93274429d6355959f1e4374c2147bb81ea649?sort=total-citations
venue: EMNLP
year: 2019
