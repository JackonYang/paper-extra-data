authors:
- Zhilin Yang
- Zihang Dai
- Yiming Yang
- J. Carbonell
- R. Salakhutdinov
- Quoc V. Le
badges:
- id: OPEN_ACCESS
corpusId: 195069387
fieldsOfStudy:
- Computer Science
meta_key: 2019-xlnet-generalized-autoregressive-pretraining-for-language-understanding
numCitedBy: 4296
numCiting: 48
paperAbstract: With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.
ref_count: 48
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 34668
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-albert-a-lite-bert-for-self-supervised-learning-of-language-representations
  numCitedBy: 2773
  pid: 7a064df1aeada7e69e5173f7d4c8606f4470365b
  show_ref_link: true
  title: ALBERT - A Lite BERT for Self-supervised Learning of Language Representations
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-made-masked-autoencoder-for-distribution-estimation
  numCitedBy: 515
  pid: 90f72fbbe5f0a29e627db28999e01a30a9655bc6
  show_ref_link: false
  title: MADE - Masked Autoencoder for Distribution Estimation
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-character-level-language-modeling-with-deeper-self-attention
  numCitedBy: 219
  pid: b9de9599d7241459db9213b5cdd7059696f5ef8d
  show_ref_link: true
  title: Character-Level Language Modeling with Deeper Self-Attention
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-multi-task-deep-neural-networks-for-natural-language-understanding
  numCitedBy: 741
  pid: 658721bc13b0fa97366d38c05a96bf0a9f4bb0ac
  show_ref_link: true
  title: Multi-Task Deep Neural Networks for Natural Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-revisiting-lstm-networks-for-semi-supervised-text-classification-via-mixed-objective-function
  numCitedBy: 73
  pid: c3f89364aecd661eb032840d2fe3efd0f6d1698c
  show_ref_link: false
  title: Revisiting LSTM Networks for Semi-Supervised Text Classification via Mixed Objective Function
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-maskgan-better-text-generation-via-filling-in-the-______
  numCitedBy: 352
  pid: 7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d
  show_ref_link: false
  title: MaskGAN - Better Text Generation via Filling in the ______
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-learned-in-translation-contextualized-word-vectors
  numCitedBy: 712
  pid: bc8fa64625d9189f5801837e7b133e7fe3c581f7
  show_ref_link: true
  title: Learned in Translation - Contextualized Word Vectors
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-transformer-xl-attentive-language-models-beyond-a-fixed-length-context
  numCitedBy: 1789
  pid: c4744a7c2bb298e4a52289a1e085c71cc3d37bc6
  show_ref_link: true
  title: Transformer-XL - Attentive Language Models beyond a Fixed-Length Context
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-breaking-the-softmax-bottleneck-a-high-rank-rnn-language-model
  numCitedBy: 277
  pid: ef9ddbc35676ce8ffc2a8067044473727839dbac
  show_ref_link: false
  title: Breaking the Softmax Bottleneck - A High-Rank RNN Language Model
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-attention-is-all-you-need
  numCitedBy: 35966
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-adaptive-input-representations-for-neural-language-modeling
  numCitedBy: 210
  pid: d170bd486e4c0fe82601e322b0e9e0dde63ab299
  show_ref_link: false
  title: Adaptive Input Representations for Neural Language Modeling
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-roberta-a-robustly-optimized-bert-pretraining-approach
  numCitedBy: 7556
  pid: 077f8329a7b6fa3b7c877a57b81eb6c18b5f87de
  show_ref_link: true
  title: RoBERTa - A Robustly Optimized BERT Pretraining Approach
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-semi-supervised-sequence-learning
  numCitedBy: 888
  pid: 4aa9f5150b46320f534de4747a2dd0cd7f3fe292
  show_ref_link: false
  title: Semi-supervised Sequence Learning
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-deep-contextualized-word-representations
  numCitedBy: 8062
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-snorkel-rapid-training-data-creation-with-weak-supervision
  numCitedBy: 623
  pid: 18bc1d4271abe8dd6e16179cdb06524a4f396e16
  show_ref_link: false
  title: Snorkel - Rapid Training Data Creation with Weak Supervision
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding
  numCitedBy: 2690
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  show_ref_link: true
  title: GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-bam-born-again-multi-task-networks-for-natural-language-understanding
  numCitedBy: 141
  pid: ef6948edae12eba6f1d486b8600108b9762f36ab
  show_ref_link: false
  title: BAM! Born-Again Multi-Task Networks for Natural Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-universal-language-model-fine-tuning-for-text-classification
  numCitedBy: 2283
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  show_ref_link: true
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-unsupervised-data-augmentation
  numCitedBy: 191
  pid: 3562fefb64cd63ac1a6a0adbaa83ae73dd674243
  show_ref_link: false
  title: Unsupervised Data Augmentation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-adversarial-training-methods-for-semi-supervised-text-classification
  numCitedBy: 589
  pid: 2cd55ded95d5d13430edfa223ba591b514ebe8a5
  show_ref_link: false
  title: Adversarial Training Methods for Semi-Supervised Text Classification
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-virtual-adversarial-training-for-semi-supervised-text-classification
  numCitedBy: 93
  pid: 93d8d45fe8101545ae6d9fab3dbb38f904ff7b4e
  show_ref_link: false
  title: Virtual Adversarial Training for Semi-Supervised Text Classification
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-neural-autoregressive-distribution-estimation
  numCitedBy: 211
  pid: 3cccc93064dae265eeb7bc76d02cdc67c942f0a5
  show_ref_link: false
  title: Neural Autoregressive Distribution Estimation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-sentencepiece-a-simple-and-language-independent-subword-tokenizer-and-detokenizer-for-neural-text-processing
  numCitedBy: 1550
  pid: b5246fa284f86b544a7c31f050b3bd0defd053fd
  show_ref_link: false
  title: SentencePiece - A simple and language independent subword tokenizer and detokenizer for Neural Text Processing
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-a-surprisingly-robust-trick-for-the-winograd-schema-challenge
  numCitedBy: 82
  pid: c57298fe3faf87f9f24414821b0df7ebb7634320
  show_ref_link: false
  title: A Surprisingly Robust Trick for the Winograd Schema Challenge
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-end-to-end-neural-ad-hoc-ranking-with-kernel-pooling
  numCitedBy: 417
  pid: ea738439b880ad033ff01602ea52d04b366d0d37
  show_ref_link: false
  title: End-to-End Neural Ad-hoc Ranking with Kernel Pooling
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-squad-100-000-questions-for-machine-comprehension-of-text
  numCitedBy: 4308
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  show_ref_link: true
  title: SQuAD - 100,000+ Questions for Machine Comprehension of Text
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books
  numCitedBy: 1441
  pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  show_ref_link: true
  title: Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-convolutional-neural-networks-for-soft-matching-n-grams-in-ad-hoc-search
  numCitedBy: 248
  pid: fc3384d631f5e2b2a9d66623d4d3e1d28b96dee7
  show_ref_link: false
  title: Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-know-what-you-don-t-know-unanswerable-questions-for-squad
  numCitedBy: 1422
  pid: 4d1c856275744c0284312a3a50efb6ca9dc4cd4c
  show_ref_link: true
  title: Know What You Don't Know - Unanswerable Questions for SQuAD
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-improving-question-answering-with-external-knowledge
  numCitedBy: 45
  pid: 6642ad0b2fd2bf834388b804250eb9337ceb3f88
  show_ref_link: false
  title: Improving Question Answering with External Knowledge
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-deep-pyramid-convolutional-neural-networks-for-text-categorization
  numCitedBy: 351
  pid: 718e1b453fe9dce79458e0db035091db603775fb
  show_ref_link: false
  title: Deep Pyramid Convolutional Neural Networks for Text Categorization
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-a-deep-relevance-matching-model-for-ad-hoc-retrieval
  numCitedBy: 674
  pid: d51ed05fd05b9d222427a05a87ed88217447b44f
  show_ref_link: false
  title: A Deep Relevance Matching Model for Ad-hoc Retrieval
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2020-dual-co-matching-network-for-multi-choice-reading-comprehension
  numCitedBy: 78
  pid: 8c473a8adca5635c3cde5af793ed7b68afec9d77
  show_ref_link: false
  title: Dual Co-Matching Network for Multi-choice Reading Comprehension
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-word-entity-duet-representations-for-document-ranking
  numCitedBy: 100
  pid: 318e25144389e7ad26ea6350ab2243b2b304a35b
  show_ref_link: false
  title: Word-Entity Duet Representations for Document Ranking
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-option-comparison-network-for-multiple-choice-reading-comprehension
  numCitedBy: 40
  pid: df06490403fb4cb3d097160d09093e13777e8362
  show_ref_link: false
  title: Option Comparison Network for Multiple-choice Reading Comprehension
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-character-level-convolutional-networks-for-text-classification
  numCitedBy: 3501
  pid: 51a55df1f023571a7e07e338ee45a3e3d66ef73e
  show_ref_link: true
  title: Character-level Convolutional Networks for Text Classification
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 1999-modeling-high-dimensional-discrete-data-with-multi-layer-neural-networks
  numCitedBy: 124
  pid: 190e4800c67ef445e4bd0944a55debaccebcf43f
  show_ref_link: false
  title: Modeling High-Dimensional Discrete Data with Multi-Layer Neural Networks
  year: 1999
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-race-large-scale-reading-comprehension-dataset-from-examinations
  numCitedBy: 707
  pid: 636a79420d838eabe4af7fb25d6437de45ab64e8
  show_ref_link: true
  title: RACE - Large-scale ReAding Comprehension Dataset From Examinations
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-improving-language-understanding-by-generative-pre-training
  numCitedBy: 3591
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  show_ref_link: true
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-newsqa-a-machine-comprehension-dataset
  numCitedBy: 590
  pid: 3eda43078ae1f4741f09be08c4ecab6229046a5c
  show_ref_link: true
  title: NewsQA - A Machine Comprehension Dataset
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-pixel-recurrent-neural-networks
  numCitedBy: 1762
  pid: 41f1d50c85d3180476c4c7b3eea121278b0d8474
  show_ref_link: false
  title: Pixel Recurrent Neural Networks
  year: 2016
slug: XLNet:-Generalized-Autoregressive-Pretraining-for-Yang-Dai
title: XLNet - Generalized Autoregressive Pretraining for Language Understanding
url: https://www.semanticscholar.org/paper/XLNet:-Generalized-Autoregressive-Pretraining-for-Yang-Dai/e0c6abdbdecf04ffac65c440da77fb9d66bb474c?sort=total-citations
venue: NeurIPS
year: 2019
