authors:
- J. Schulman
- F. Wolski
- Prafulla Dhariwal
- Alec Radford
- Oleg Klimov
badges:
- id: OPEN_ACCESS
corpusId: 28695052
fieldsOfStudy:
- Computer Science
meta_key: 2017-proximal-policy-optimization-algorithms
numCitedBy: 6094
numCiting: 15
paperAbstract: We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.
ref_count: 15
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-trust-region-policy-optimization
  numCitedBy: 3977
  pid: 66cdc28dc084af6507e979767755e99fe0b46b39
  show_ref_link: false
  title: Trust Region Policy Optimization
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-high-dimensional-continuous-control-using-generalized-advantage-estimation
  numCitedBy: 1689
  pid: d316c82c12cf4c45f9e85211ef3d1fa62497bff8
  show_ref_link: false
  title: High-Dimensional Continuous Control Using Generalized Advantage Estimation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-asynchronous-methods-for-deep-reinforcement-learning
  numCitedBy: 5389
  pid: 69e76e16740ed69f4dc55361a3d319ac2f1293dd
  show_ref_link: false
  title: Asynchronous Methods for Deep Reinforcement Learning
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-emergence-of-locomotion-behaviours-in-rich-environments
  numCitedBy: 626
  pid: a762ae907b7dd71a59bd8bd98aba69dfe2de13a2
  show_ref_link: false
  title: Emergence of Locomotion Behaviours in Rich Environments
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-sample-efficient-actor-critic-with-experience-replay
  numCitedBy: 550
  pid: 6a43d91c8d883e3463b358571125fa0ec7298b3a
  show_ref_link: false
  title: Sample Efficient Actor-Critic with Experience Replay
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-benchmarking-deep-reinforcement-learning-for-continuous-control
  numCitedBy: 1260
  pid: 1464776f20e2bccb6182f183b5ff2e15b0ae5e56
  show_ref_link: false
  title: Benchmarking Deep Reinforcement Learning for Continuous Control
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-the-arcade-learning-environment-an-evaluation-platform-for-general-agents-extended-abstract
  numCitedBy: 2086
  pid: f82e4ff4f003581330338aaae71f60316e58dd26
  show_ref_link: false
  title: The Arcade Learning Environment - An Evaluation Platform for General Agents (Extended Abstract)
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2004-simple-statistical-gradient-following-algorithms-for-connectionist-reinforcement-learning
  numCitedBy: 5268
  pid: 4c915c1eecb217c123a36dc6d3ce52d12c742614
  show_ref_link: true
  title: Simple statistical gradient-following algorithms for connectionist reinforcement learning
  year: 2004
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-adam-a-method-for-stochastic-optimization
  numCitedBy: 91740
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  show_ref_link: true
  title: Adam - A Method for Stochastic Optimization
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-human-level-control-through-deep-reinforcement-learning
  numCitedBy: 16393
  pid: e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d
  show_ref_link: true
  title: Human-level control through deep reinforcement learning
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2012-mujoco-a-physics-engine-for-model-based-control
  numCitedBy: 2804
  pid: b354ee518bfc1ac0d8ac447eece9edb69e92eae1
  show_ref_link: false
  title: MuJoCo - A physics engine for model-based control
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: 2006-learning-tetris-using-the-noisy-cross-entropy-method
  numCitedBy: 222
  pid: 0ff188986e48d17fc4b59e6c4c00681794c9fd08
  show_ref_link: false
  title: Learning Tetris Using the Noisy Cross-Entropy Method
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-openai-gym
  numCitedBy: 2542
  pid: ff7f3277c6fa759e84e1ab7664efdac1c1cec76b
  show_ref_link: false
  title: OpenAI Gym
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2002-approximately-optimal-approximate-reinforcement-learning
  numCitedBy: 665
  pid: 523b4ce1c2a1336962444abc1dec215756c2f3e6
  show_ref_link: false
  title: Approximately Optimal Approximate Reinforcement Learning
  year: 2002
slug: Proximal-Policy-Optimization-Algorithms-Schulman-Wolski
title: Proximal Policy Optimization Algorithms
url: https://www.semanticscholar.org/paper/Proximal-Policy-Optimization-Algorithms-Schulman-Wolski/dce6f9d4017b1785979e7520fd0834ef8cf02f4b?sort=total-citations
venue: ArXiv
year: 2017
