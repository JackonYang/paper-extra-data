authors:
- Bichen Wu
- Xiaoliang Dai
- Peizhao Zhang
- Yanghan Wang
- Fei Sun
- Yiming Wu
- Yuandong Tian
- "P\xE9ter Vajda"
- Yangqing Jia
- K. Keutzer
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 54461508
fieldsOfStudy:
- Computer Science
meta_key: 2019-fbnet-hardware-aware-efficient-convnet-design-via-differentiable-neural-architecture-search
numCitedBy: 731
numCiting: 37
paperAbstract: Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too resource demanding for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets (Facebook-Berkeley-Nets), a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4x smaller and 1.5x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4x speedup on an iPhone X. FBNet models are open-sourced at https://github. com/facebookresearch/mobile-vision.
ref_count: 37
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-mnasnet-platform-aware-neural-architecture-search-for-mobile
  numCitedBy: 1613
  pid: 693c97ecedb0a84539b7162c95e89fa3cd84ca73
  show_ref_link: true
  title: MnasNet - Platform-Aware Neural Architecture Search for Mobile
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-mixed-precision-quantization-of-convnets-via-differentiable-neural-architecture-search
  numCitedBy: 138
  pid: b6b918fd7f5162fe28c88743db276bffc080576b
  show_ref_link: false
  title: Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-squeezenext-hardware-aware-neural-network-design
  numCitedBy: 150
  pid: b5c03413b37f06bd94144ebfae5b2e0632ca604e
  show_ref_link: false
  title: SqueezeNext - Hardware-Aware Neural Network Design
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design
  numCitedBy: 1910
  pid: c02b909a514af6b9255315e2d50112845ca5ed0e
  show_ref_link: true
  title: ShuffleNet V2 - Practical Guidelines for Efficient CNN Architecture Design
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-efficient-neural-architecture-search-via-parameter-sharing
  numCitedBy: 1735
  pid: fe9b8aac9fa3bfd9724db5a881a578e471e612d7
  show_ref_link: true
  title: Efficient Neural Architecture Search via Parameter Sharing
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-amc-automl-for-model-compression-and-acceleration-on-mobile-devices
  numCitedBy: 843
  pid: 1717255b6aea01fe956cef998abbc3c399b5d7cf
  show_ref_link: true
  title: AMC - AutoML for Model Compression and Acceleration on Mobile Devices
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-learning-time-memory-efficient-deep-architectures-with-budgeted-super-networks
  numCitedBy: 66
  pid: 3b8aa7a38bc60f7b42757e53a0801f6e71dcef5c
  show_ref_link: false
  title: Learning Time/Memory-Efficient Deep Architectures with Budgeted Super Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-netadapt-platform-aware-neural-network-adaptation-for-mobile-applications
  numCitedBy: 324
  pid: d16b21f3e99171c86365679435f9f03766750639
  show_ref_link: true
  title: NetAdapt - Platform-Aware Neural Network Adaptation for Mobile Applications
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices
  numCitedBy: 3251
  pid: 9da734397acd7ff7c557960c62fb1b400b27bd89
  show_ref_link: true
  title: ShuffleNet - An Extremely Efficient Convolutional Neural Network for Mobile Devices
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-synetgy-algorithm-hardware-co-design-for-convnet-accelerators-on-embedded-fpgas
  numCitedBy: 70
  pid: 3cc6c2db24a2a14560f151867f2ac0b681ec3238
  show_ref_link: false
  title: Synetgy - Algorithm-hardware Co-design for ConvNet Accelerators on Embedded FPGAs
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-squeezedet-unified-small-low-power-fully-convolutional-neural-networks-for-real-time-object-detection-for-autonomous-driving
  numCitedBy: 369
  pid: 804aedfa1d732617cf5b9f59726b7f2e28fbbfb0
  show_ref_link: false
  title: SqueezeDet - Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-darts-differentiable-architecture-search
  numCitedBy: 2237
  pid: c1f457e31b611da727f9aef76c283a18157dfa83
  show_ref_link: true
  title: DARTS - Differentiable Architecture Search
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-level-accuracy-with-50-x-fewer-parameters-and-0-5-mb-model-size
  numCitedBy: 687
  pid: 592d2e65489f23ebd993dbdc0c84eda9ac8aadbe
  show_ref_link: false
  title: '- LEVEL ACCURACY WITH 50 X FEWER PARAMETERS AND < 0 . 5 MB MODEL SIZE'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-learning-transferable-architectures-for-scalable-image-recognition
  numCitedBy: 3538
  pid: d0611891b9e8a7c5731146097b6f201578f47b2f
  show_ref_link: true
  title: Learning Transferable Architectures for Scalable Image Recognition
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-snas-stochastic-neural-architecture-search
  numCitedBy: 626
  pid: 3f0a2de309f21a957b4741dd68007eb08d9b12e3
  show_ref_link: false
  title: SNAS - Stochastic Neural Architecture Search
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-progressive-neural-architecture-search
  numCitedBy: 1377
  pid: 5f79398057bf0bbda9ff50067bc1f2950c2a2266
  show_ref_link: true
  title: Progressive Neural Architecture Search
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications
  numCitedBy: 10323
  pid: 3647d6d0f151dc05626449ee09cc7bce55be497e
  show_ref_link: true
  title: MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-mobilenetv2-inverted-residuals-and-linear-bottlenecks
  numCitedBy: 7406
  pid: dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4
  show_ref_link: true
  title: MobileNetV2 - Inverted Residuals and Linear Bottlenecks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-condensenet-an-efficient-densenet-using-learned-group-convolutions
  numCitedBy: 516
  pid: efbac99adf8628aae7f070e5b4388a295956f9d2
  show_ref_link: false
  title: CondenseNet - An Efficient DenseNet Using Learned Group Convolutions
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-neural-architecture-search-with-reinforcement-learning
  numCitedBy: 3482
  pid: 67d968c7450878190e45ac7886746de867bf673d
  show_ref_link: true
  title: Neural Architecture Search with Reinforcement Learning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-going-deeper-with-convolutions
  numCitedBy: 29917
  pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  show_ref_link: true
  title: Going deeper with convolutions
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-very-deep-convolutional-networks-for-large-scale-image-recognition
  numCitedBy: 63195
  pid: eb42cf88027de515750f230b23b1a057dc782108
  show_ref_link: true
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2016-deep-residual-learning-for-image-recognition
  numCitedBy: 97653
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-shift-a-zero-flop-zero-parameter-alternative-to-spatial-convolutions
  numCitedBy: 214
  pid: 70c810ba62c5ee40d611e134b2ac2ca61c4de16b
  show_ref_link: false
  title: Shift - A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2018-squeezeseg-convolutional-neural-nets-with-recurrent-crf-for-real-time-road-object-segmentation-from-3d-lidar-point-cloud
  numCitedBy: 428
  pid: cb8e4bdd69248146bc42aacc45929a9dbfe44081
  show_ref_link: false
  title: SqueezeSeg - Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: 2019-squeezesegv2-improved-model-structure-and-unsupervised-domain-adaptation-for-road-object-segmentation-from-a-lidar-point-cloud
  numCitedBy: 263
  pid: c524a8fe1ae29844627c163dd4efeb0cebc032c1
  show_ref_link: false
  title: SqueezeSegV2 - Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 2017-automatic-differentiation-in-pytorch
  numCitedBy: 10485
  pid: b36a5bb1707bb9c70025294b3a310138aae8327a
  show_ref_link: true
  title: Automatic differentiation in PyTorch
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: 2015-adam-a-method-for-stochastic-optimization
  numCitedBy: 91740
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  show_ref_link: true
  title: Adam - A Method for Stochastic Optimization
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: 2009-imagenet-a-large-scale-hierarchical-image-database
  numCitedBy: 28266
  pid: d2c733e34d48784a37d717fe43d9e93277a8c53e
  show_ref_link: true
  title: ImageNet - A large-scale hierarchical image database
  year: 2009
- fieldsOfStudy:
  - Computer Science
  - Mathematics
  meta_key: 2017-categorical-reparameterization-with-gumbel-softmax
  numCitedBy: 2766
  pid: 29e944711a354c396fad71936f536e83025b6ce0
  show_ref_link: false
  title: Categorical Reparameterization with Gumbel-Softmax
  year: 2017
- fieldsOfStudy:
  - Computer Science
  - Mathematics
  meta_key: 2017-the-concrete-distribution-a-continuous-relaxation-of-discrete-random-variables
  numCitedBy: 1627
  pid: 515a21e90117941150923e559729c59f5fdade1c
  show_ref_link: false
  title: The Concrete Distribution - A Continuous Relaxation of Discrete Random Variables
  year: 2017
- fieldsOfStudy:
  - Medicine
  meta_key: 2012-et-al
  numCitedBy: 58258
  pid: bc6dff14a130c57a91d5a21339c23471faf1d46f
  show_ref_link: false
  title: Et al
  year: 2012
- fieldsOfStudy: []
  meta_key: 2021-l
  numCitedBy: 29765
  pid: cbe020b715b548694bad73e49c5d72854670d6e7
  show_ref_link: false
  title: "\u2018L'"
  year: 2021
slug: FBNet:-Hardware-Aware-Efficient-ConvNet-Design-via-Wu-Dai
title: FBNet - Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search
url: https://www.semanticscholar.org/paper/FBNet:-Hardware-Aware-Efficient-ConvNet-Design-via-Wu-Dai/45532bffbfbb5553da0b2d0844e95a1b37e59147?sort=total-citations
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
